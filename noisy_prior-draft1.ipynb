{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Noisy prior model of SPE by learners of monolingual and contact Spanish\"\n",
    "output:\n",
    "  word_document: default\n",
    "  html_document:\n",
    "    df_print: paged\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#DO NOT USE plyr library. It will interfere with group by and summarise operations in code chunks 'priors' and 'likelihoods' below (even if called first).\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a revised model of how learners calculate the posterior `P(pronoun|reference)`. Unlike the baseline optimal modl, this model assumes a NOISY learner who inaccurately calculates the posterior by occasionally omitting the prior `P(pronoun)`. Like the baseline optimal model, this model still assumes that the learner accurately learns both the prior `P(pronoun)` and the likelihood `P(reference|pronoun)` from the input.\n",
    "\n",
    "We will look at the saem two populations. \n",
    "\n",
    "The code below loads Mexican and Villa 21 data, coded for form, reference, and other attributes. It only needs to be run if the optimal model has not already been run in the same R session.\n",
    "\n",
    "# Assumptions about the input\n",
    "\n",
    "Assumptions about what constitutes the input are the same as in the optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#put Mexico City and Buenos Aires together into a single aduchi dataset and format its variables according to the above assumptions.\n",
    "aduchi <- read_csv(\"aduchi.csv\")\n",
    "\n",
    "aduchi <- aduchi %>% \n",
    "  select(community, file, participant, dyad, SES, stem, animacy, nullovert, reference_turn, person, number, tma, yr, mo) %>%\n",
    "  filter(\n",
    "    animacy == 1 & \n",
    "      nullovert %in% c(0, 1) & \n",
    "      reference_turn %in% c(\"same\", \"switch\") &\n",
    "      #exclude usted(es), following Shin 2016\n",
    "      person %in% c(\"1\", \"2\", \"3\") & \n",
    "      number %in% c(\"s\", \"p\", \"S\", \"P\") &\n",
    "      tma %in% c(\"cond\", \"fut=\", \"pas\", \"pres\", \"PRES\", \"pret\", \"PRET\", \"sub&pres\")\n",
    "  ) %>% mutate(\n",
    "    #make the outcome variable numeric\n",
    "    SPE = as.numeric(paste(nullovert)),\n",
    "    #rename the reference variable\n",
    "    ref = reference_turn,\n",
    "    #create personnum factor following Shin 2016\n",
    "    personnum = as.factor(paste0(person, tolower(number))),\n",
    "    #create TMA factor following Shin 2016\n",
    "    tma = recode(tma, \"pres\"=\"present\", \"PRES\"=\"present\",\"pret\"=\"preterite\", \"PRET\"=\"preterite\", \"pas\"=\"imperfect\", \"sub&pres\"=\"other\", \"cond\"=\"other\", \"fut=\"=\"other\")\n",
    "  ) %>% filter(\n",
    "    #filter out a coding mistake\n",
    "    personnum != \"2p\"\n",
    "  ) %>% mutate(\n",
    "    #relevel personnum and tma\n",
    "    personnum = fct_relevel(personnum, \"1s\", \"2s\", \"3s\", \"1p\", \"3p\"),\n",
    "    tma = fct_relevel(tma, \"other\", \"imperfect\", \"preterite\", \"present\")\n",
    "  ) %>% mutate(\n",
    "    #Add child ages and age groups. \n",
    "    child_age_mo = 12*yr + mo,\n",
    "    child_age_yr = child_age_mo / 12,\n",
    "    #Note: use 2 age groups - must be split at 56 to prevent missing values\n",
    "    child_age_group = cut(child_age_mo, breaks = c(-Inf, 56, Inf), labels=c(\"younger\", \"older\"), right = FALSE)\n",
    "  ) %>% mutate(\n",
    "    #split primary dataset into input and output\n",
    "    inputoutput = ifelse(participant == \"CHI\", \"output\", \"input\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "This model is a mixture between:\n",
    "\n",
    " - the optimal model, which uses both likelihood and prior to accurately calculate the posterior: $P_{OPTIMAL}(overt|reference) \\propto P(reference|overt)\\times P(overt)$\n",
    " - a model that omits the prior: $P_{NOISY}(overt|reference) \\propto P(reference|overt)$\n",
    " \n",
    "The degree of omission is determined by how much the optimal and noisy models each contributes to the posterior, as controlled by the parameter $0 \\leq \\beta_{PRIOR} \\leq 1$. The larger $\\beta_{PRIOR}$, the more the learner uses the prior.:\n",
    "\n",
    "$P(overt|reference) = \\beta_{PRIOR} * P_{OPTIMAL}(overt|reference) + (1-\\beta_{PRIOR}) * P_{NOISY}$\n",
    "\n",
    "## Priors\n",
    "\n",
    "As with the optimal model, priors are learned accurately from the input that the child receives. For Villa21, more Rioplatense input will result in a lower prior and more Paraguayan input will result in a higher prior. The last column is the prior probability of null (`SPE=0`) and overt (`SPE=1`) in each community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#Form a tibble with the prior of each form in each community\n",
    "priors <- aduchi %>% \n",
    "  filter(inputoutput == \"input\") %>%\n",
    "  group_by(community, SPE) %>%\n",
    "dplyr::summarise(n = n()) %>%\n",
    "  mutate(\n",
    "    freq = n/sum(n)\n",
    "  )\n",
    "\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihoods\n",
    "\n",
    "As with the optimal model, likelihoods are also learned accurately from the input. For Villa21, more Rioplatense input will not change the likelihoods, since both dialects condition pronoun realization on reference *to the same degree*. The last column is the likelihood of each reference context, given an overt or null pronoun - calculated for each community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "ref_likelihoods <- aduchi %>% \n",
    "  filter(inputoutput == \"input\") %>%\n",
    "    group_by(community, SPE, ref) %>%\n",
    "    dplyr::summarise(\n",
    "      n = n()\n",
    "    ) %>%\n",
    "    mutate(\n",
    "      freq = n/sum(n)\n",
    "    )\n",
    "print(ref_likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posteriors\n",
    "Posteriors are calculated through a probabilistic mix of accurate and inaccurate use of the prior and likelihoods. Spelling out the equation from above more fully:\n",
    "\n",
    "$P(overt|reference) = \\beta_{PRIOR} \\frac{P(reference|overt)\\times P(overt)}{ \\sum_{pro = \\{ null, overt \\}} P(reference|pro)\\times P(pro) } + (1-\\beta_{PRIOR}) \\frac{P(reference|overt)}{ \\sum_{pro = \\{ null, overt \\}} P(reference|pro) }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "noisy_prior <- function(c, r, beta) {\n",
    "  #priors \n",
    "  prior_o <- priors$freq[priors$community == c & priors$SPE == 1]\n",
    "  prior_n <- priors$freq[priors$community == c & priors$SPE == 0]\n",
    "  \n",
    "  #likelihoods \n",
    "  lik_ref_o <- ref_likelihoods$freq[ref_likelihoods$community == c & ref_likelihoods$ref == r & ref_likelihoods$SPE == 1]\n",
    "  lik_ref_n <- ref_likelihoods$freq[ref_likelihoods$community == c & ref_likelihoods$ref == r & ref_likelihoods$SPE == 0]\n",
    "  \n",
    "  #optimal calculation uses both priors and likelihoods\n",
    "  posterior_opt <- (lik_ref_o * prior_o)/\n",
    "    (lik_ref_o * prior_o +\n",
    "       lik_ref_n * prior_n)\n",
    "  \n",
    "  #non-optimal calculation uses only likelihoods\n",
    "  posterior_noisy <- (lik_ref_o)/\n",
    "    (lik_ref_o +\n",
    "       lik_ref_n * prior_n)\n",
    "  \n",
    "  #mixing them together, with beta = weight of the model WITH a prior\n",
    "  posterior <- beta*posterior_opt + (1-beta)*posterior_noisy\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted versus observed proportion overt\n",
    "\n",
    "In order to find the best possible prediction of this model, we find the value of $\\beta_{PRIOR}$ that minimizes mean squared error between observed and predicted % overt SPE in each context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#create all levels of beta_PRIOR to test\n",
    "beta_PRIOR <- tibble(\"beta_PRIOR\" = seq(from = 0, to = 1, by = 0.01)) \n",
    "\n",
    "#calculate observed % overt in each context\n",
    "observed <- aduchi %>% \n",
    "  filter(inputoutput == \"output\") %>%\n",
    "  group_by(\n",
    "   community, ref\n",
    "  ) %>%\n",
    "  summarise(\n",
    "    overt = sum(SPE),\n",
    "    tokens = n(),\n",
    "    observed = overt/tokens\n",
    "  ) \n",
    "\n",
    "#calculate predicted % overt for each combination of context and beta_PRIOR\n",
    "predictions <- observed %>%\n",
    "  merge(beta_PRIOR, all = TRUE) %>%\n",
    "  arrange(beta_PRIOR, community, ref) %>%\n",
    "  rowwise() %>%\n",
    "  mutate(\n",
    "    predicted = noisy_prior(community, ref, beta_PRIOR)\n",
    "  )\n",
    "\n",
    "#compare observed to predicted % overt for each value of beta_PRIOR\n",
    "fit <- predictions %>% ungroup() %>%\n",
    "  mutate(\n",
    "     error = observed - predicted\n",
    "  ) %>%\n",
    "  group_by(beta_PRIOR, community) %>%\n",
    "  summarise(\n",
    "    MSE = mean(error*error)\n",
    "  ) %>% arrange(community, MSE)\n",
    "\n",
    "print(observed)\n",
    "print(predictions)\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit: **start editing here**\n",
    "\n",
    "The mean squared error of the optimal model for each community is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Pick the beta_PRIOR with the lowest MSE in each community\n",
    "# fit %>% group_by(community) %>%\n",
    "#   filter(MSE == min(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's likelihodd given the data is calculated by first assuming that the model is true and then calculating the probability of observing the data that we have observed in our sample. If the model actually is true (or at least, a better hypothesis than other models), this probability should be high, but if it is untrue (or at least, a worse hypothesis than other models) the probability should be low. \n",
    "\n",
    "Assuming that the optimal model is true, the probability of observing $N_{overt}$ overt pronouns and $N_{null}$ null pronouns in any given context is equal to $P(N_{overt} | P_{predicted}(overt)) \\times P(N_{null} | P_{predicted}(null))$. For example, in same-reference contexts, the predicted probability of overt and null pronouns for Mexico City kids is $P_{predicted}(overt) = 0.056$ and $P_{predicted}(null) = 1 - 0.056 = 0.944$, respectively, and the observed count of overt and null pronouns is $N_{overt} = 44$ and $N_{null} = 603-44 = 559$, respectively. Thus, the probability of the observed data is\n",
    "\n",
    "$P(N_{overt}=44 | P_{predicted}(overt)=.056) \\times P(N_{null}=559 | P_{predicted}(null)=.944) = 0.056^{44} \\times 0.944^{559} = 8.504*10^{-70}$\n",
    "\n",
    "To get the probability of the whole dataset, we then calculate $P(N_{overt} | P_{predicted}(overt)) \\times P(N_{null} | P_{predicted}(null))$ in switch-reference environments and multiply the two together. Since these probabilities get very small, especially for datasets with many observations, we typically take the logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# loglik <- predictions %>% \n",
    "#   transmute(\n",
    "#     community = community,\n",
    "#     ref = ref,\n",
    "#     N_overt = overt,\n",
    "#     N_null = tokens - overt,\n",
    "#     predicted_overt = predicted,\n",
    "#     predicted_null = 1 - predicted,\n",
    "#     loglik = log(predicted_overt)*N_overt + log(predicted_null)*N_null\n",
    "#   ) %>% \n",
    "#   group_by(community) %>%\n",
    "#   summarise(\n",
    "#     loglik = sum(loglik)\n",
    "#   )\n",
    "# \n",
    "# print(loglik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's visualize the observed and predicted rates of overt SPE, to see where our model is over- or under-predicting pronoun rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# obs_v_opt <- predictions %>%\n",
    "#   select(-c(error, overt, tokens)) %>%\n",
    "#   gather(key = \"predicted_vs_observed\", value = \"prop_overt\", observed, predicted) %>%\n",
    "#   arrange(community, ref)\n",
    "# \n",
    "# ggplot(obs_v_opt,\n",
    "#        aes(x = ref, y = prop_overt, fill = predicted_vs_observed)) +\n",
    "#   facet_grid(community~.) +\n",
    "#   geom_col(position = \"dodge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model seems to be a better fit for the Mexico City cohort, with a lower MSE, a higher (=less negative) log likelihood and a visually better fit to the data in both same- and swith-reference contexts. Specifically, while the model under-predicts the frequency of overt SPE in both Mexico City and Villa 21, Buenos Aires, it is more severely under the mark for the latter group.\n",
    "\n",
    "<!-- When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file).  -->\n",
    "\n",
    "<!-- The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed. -->"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
